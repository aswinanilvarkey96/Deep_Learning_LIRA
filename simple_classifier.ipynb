{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhRSD_PRuqVP",
        "outputId": "dda6092b-b2d5-41db-aff6-db84da9c8add"
      },
      "source": [
        "!pip install pickle5 pandas==1.3 wandb torchinfo torchviz\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import wandb\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from random import randint\n",
        "from google.colab import drive\n",
        "import pickle5 as pickle\n",
        "import warnings\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import Image, display\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n",
            "Requirement already satisfied: pandas==1.3 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.7)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.4)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3) (1.15.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.1.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.10.0+cu111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWXi-oWOuzjZ"
      },
      "source": [
        "# Load Data\n",
        "def load_data():\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  local_path = 'drive/My Drive/deep_learning/assignment/datasets/'\n",
        "  #local_path = \"C:/Users/simon/Nextcloud2/Master/Deep Learning/assignment/\"\n",
        "  data_path = local_path + \"dataset_big_boi_unscaled.pickle\"\n",
        "\n",
        "  with open(data_path, \"rb\") as fh:\n",
        "    dataset = pickle.load(fh)\n",
        "  return dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ekKRqUu41v"
      },
      "source": [
        "def build_dataset(batch_size,max_iri_value):\n",
        "  #if \"dataset\" not in globals():\n",
        "  print(\"Loading Dataset\")\n",
        "  dataset = load_data()\n",
        "\n",
        "  #data_shape_old = dataset[\"train\"].shape\n",
        "  #train_set = dataset[\"train\"][[\"z\",\"IRI_mean\"]].drop(dataset[\"train\"][[\"z\",\"IRI_mean\"]][dataset[\"train\"][\"IRI_mean\"]>max_iri_value].index)\n",
        "  train_set = dataset[\"train\"][[\"z\",\"IRI_mean\"]][0:20]\n",
        "  test_set = dataset[\"test\"][[\"z\",\"IRI_mean\"]][0:20]\n",
        "  #print(f\"Shape of dataset: {data_shape_old}, after max iri: {train_set_l.shape}\")\n",
        "  #train_set_high_iri = dataset[\"train\"][[\"z\",\"IRI_mean\"]].drop(dataset[\"train\"][[\"z\",\"IRI_mean\"]][dataset[\"train\"][\"IRI_mean\"]<=max_iri_value].index)\n",
        "  #train_set = train_set_l[\"z\"].values\n",
        "  #test_set = dataset[\"test\"][\"z\"].values\n",
        "  #print(f\"Dataset length reduced: {dataset['train'].shape[0]} -> {train_set.shape[0]}\")\n",
        "  return dataset, train_set, test_set"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_pgvTdu19b"
      },
      "source": [
        "def build_model(device):\n",
        "  class Model(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Model, self).__init__()\n",
        "          self.linear1 = torch.nn.Linear(3085,600)\n",
        "          self.linear2 = torch.nn.Linear(600,60)\n",
        "          self.linear3 = torch.nn.Linear(60,2)\n",
        "          self.relu = torch.nn.ReLU()   \n",
        "          self.sm = torch.nn.Softmax()       \n",
        "          \n",
        "      def forward(self, x):\n",
        "          x = self.linear1(x)\n",
        "          x = self.linear2(self.relu(x))\n",
        "          return self.sm(self.linear3(self.relu(x)))\n",
        "\n",
        "  return Model().to(device)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Wf_VMsxGjA"
      },
      "source": [
        "def build_optimizer(model,learning_rate):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "  return optimizer,loss_function"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxywDGRXytVg"
      },
      "source": [
        "def train_epoch(epoch, model, train_set, test_set, optimizer, loss_function, device, batch_size,y_train,y_test):\n",
        "  train_loss = 0\n",
        "  test_loss = 0\n",
        "  #rng = np.random.default_rng(epoch)\n",
        "  #rng.shuffle(train_set,axis=0)\n",
        "  #rng.shuffle(test_set, axis=0)\n",
        "\n",
        "  model.train()\n",
        "  for idx in range(train_set[\"z\"].shape[0]//batch_size):\n",
        "      batch = np.zeros((batch_size,1,train_set[\"z\"].iloc[0].shape[0]))\n",
        "\n",
        "      for b in range(batch_size):\n",
        "        batch[b][0]=train_set[\"z\"].values[idx*batch_size+b]\n",
        "\n",
        "      batch = torch.from_numpy(batch.astype(np.float32)).to(device)\n",
        "      output = model(batch)\n",
        "      #print(f\"Output shape: {output.shape}\")\n",
        "      #print(f\"y_train shape: {y_train[idx*batch_size:idx*batch_size+batch_size].shape}\")\n",
        "\n",
        "      #print(f\"output: {output}\\n label: {y_train[idx*batch_size:idx*batch_size+batch_size].view(-1,1,1)}\")\n",
        "      loss = loss_function(output.reshape(-1,2), y_train[idx*batch_size:idx*batch_size+batch_size].reshape(-1,2))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for idx in range(test_set[\"z\"].shape[0]//batch_size):\n",
        "        batch = np.zeros((batch_size,1,test_set[\"z\"].iloc[0].shape[0]))\n",
        "        for b in range(batch_size):\n",
        "            batch[b][0]=test_set[\"z\"].values[idx*batch_size+b]\n",
        "        batch = torch.from_numpy(batch.astype(np.float32)).to(device)\n",
        "        output = model(batch)\n",
        "        loss = loss_function(output.reshape(-1,2), y_test[idx*batch_size:idx*batch_size+batch_size].reshape(-1,2))\n",
        "        test_loss += loss.item()\n",
        "\n",
        "  train_loss = train_loss/(train_set[\"z\"].shape[0]//batch_size)\n",
        "  test_loss = test_loss/(test_set[\"z\"].shape[0]//batch_size)\n",
        "  return train_loss, test_loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UbBZbNuwZmC"
      },
      "source": [
        "max_iri = 4\n",
        "epochs = 20\n",
        "batch_size=1\n",
        "\n",
        "dataset, train_set, test_set=build_dataset(1,max_iri)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = build_model(device)\n",
        "optimizer, loss_function = build_optimizer(model,2e-4)\n",
        "\n",
        "y_train = np.array([0 if v<5 else 1 for v in train_set[\"IRI_mean\"].values])\n",
        "y_test = np.array([0 if v<5 else 1 for v in test_set[\"IRI_mean\"].values])\n",
        "\n",
        "y_train = torch.nn.functional.one_hot(torch.from_numpy(y_train)).to(device).float()\n",
        "y_test = torch.nn.functional.one_hot(torch.from_numpy(y_test)).to(device).float()\n",
        "\n",
        "X_train = dataset[\"train\"][\"z\"].values\n",
        "X_test = dataset[\"test\"][\"z\"].values\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss, test_loss = train_epoch(epoch, model,train_set,test_set,optimizer,loss_function,device,batch_size,y_train,y_test)\n",
        "  \n",
        "  print(\"Epoch: [{}/{}] Train-Loss: {:.3f}, Val-Loss: {:.3f}\".format(epoch+1, \n",
        "                      epochs, train_loss, test_loss)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaTx7v4pxTSh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}